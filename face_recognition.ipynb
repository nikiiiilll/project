{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8IBUFaa-c-fF"
      },
      "outputs": [],
      "source": [
        "import cv2\n",
        "import os\n",
        "import numpy as np\n",
        "\n",
        "# Initialize Haar Cascade\n",
        "face_cascade = cv2.CascadeClassifier(cv2.data.haarcascades + 'haarcascade_frontalface_default.xml')\n",
        "\n",
        "# Directory to save faces\n",
        "data_dir = \"face_data\"\n",
        "os.makedirs(data_dir, exist_ok=True)\n",
        "\n",
        "# Step 1: Capture face samples for a person\n",
        "def collect_face_samples():\n",
        "    person_name = input(\"Enter name to register: \").strip()\n",
        "    person_path = os.path.join(data_dir, person_name)\n",
        "    os.makedirs(person_path, exist_ok=True)\n",
        "\n",
        "    cap = cv2.VideoCapture(0)\n",
        "    count = 0\n",
        "\n",
        "    print(\"[INFO] Capturing face samples. Press 'q' to quit.\")\n",
        "\n",
        "    while True:\n",
        "        ret, frame = cap.read()\n",
        "        if not ret:\n",
        "            break\n",
        "\n",
        "        gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
        "        faces = face_cascade.detectMultiScale(gray, 1.1, 4)\n",
        "\n",
        "        for (x, y, w, h) in faces:\n",
        "            face = gray[y:y+h, x:x+w]\n",
        "            face = cv2.resize(face, (200, 200))\n",
        "\n",
        "            file_path = os.path.join(person_path, f\"{count}.jpg\")\n",
        "            cv2.imwrite(file_path, face)\n",
        "            count += 1\n",
        "\n",
        "            cv2.rectangle(frame, (x, y), (x+w, y+h), (0, 255, 0), 2)\n",
        "\n",
        "        cv2.imshow(\"Capturing Faces\", frame)\n",
        "\n",
        "        if cv2.waitKey(1) & 0xFF == ord('q') or count >= 20:\n",
        "            break\n",
        "\n",
        "    cap.release()\n",
        "    cv2.destroyAllWindows()\n",
        "    print(f\"[INFO] Collected {count} images for '{person_name}'\")\n",
        "\n",
        "# Step 2: Train the recognizer\n",
        "def train_model():\n",
        "    recognizer = cv2.face.LBPHFaceRecognizer_create()\n",
        "    faces = []\n",
        "    labels = []\n",
        "    label_map = {}\n",
        "    current_label = 0\n",
        "\n",
        "    for person_name in os.listdir(data_dir):\n",
        "        person_path = os.path.join(data_dir, person_name)\n",
        "        if not os.path.isdir(person_path):\n",
        "            continue\n",
        "\n",
        "        for image_file in os.listdir(person_path):\n",
        "            image_path = os.path.join(person_path, image_file)\n",
        "            img = cv2.imread(image_path, cv2.IMREAD_GRAYSCALE)\n",
        "            faces.append(img)\n",
        "            labels.append(current_label)\n",
        "\n",
        "        label_map[current_label] = person_name\n",
        "        current_label += 1\n",
        "\n",
        "    recognizer.train(faces, np.array(labels))\n",
        "    print(\"[INFO] Training completed.\")\n",
        "    return recognizer, label_map\n",
        "\n",
        "# Step 3: Live recognition\n",
        "def recognize_faces(recognizer, label_map):\n",
        "    cap = cv2.VideoCapture(0)\n",
        "\n",
        "    print(\"[INFO] Starting live face recognition. Press 'q' to quit.\")\n",
        "\n",
        "    while True:\n",
        "        ret, frame = cap.read()\n",
        "        if not ret:\n",
        "            break\n",
        "\n",
        "        gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
        "        faces = face_cascade.detectMultiScale(gray, 1.1, 4)\n",
        "\n",
        "        for (x, y, w, h) in faces:\n",
        "            face = gray[y:y+h, x:x+w]\n",
        "            face = cv2.resize(face, (200, 200))\n",
        "\n",
        "            label, confidence = recognizer.predict(face)\n",
        "            name = label_map.get(label, \"Unknown\")\n",
        "\n",
        "            cv2.rectangle(frame, (x, y), (x+w, y+h), (0, 255, 0), 2)\n",
        "            cv2.putText(frame, f\"{name} ({confidence:.0f})\", (x, y-10),\n",
        "                        cv2.FONT_HERSHEY_SIMPLEX, 0.8, (255, 255, 255), 2)\n",
        "\n",
        "        cv2.imshow(\"Face Recognition\", frame)\n",
        "\n",
        "        if cv2.waitKey(1) & 0xFF == ord('q'):\n",
        "            break\n",
        "\n",
        "    cap.release()\n",
        "    cv2.destroyAllWindows()\n",
        "\n",
        "# ====== RUN SEQUENCE ======\n",
        "if _name_ == \"_main_\":\n",
        "    print(\"\\n1. Register new face\")\n",
        "    print(\"2. Start face recognition\")\n",
        "    choice = input(\"Select option (1 or 2): \")\n",
        "\n",
        "    if choice == '1':\n",
        "        collect_face_samples()\n",
        "    elif choice == '2':\n",
        "        recognizer, label_map = train_model()\n",
        "        recognize_faces(recognizer, label_map)\n",
        "    else:\n",
        "        print(\"‚ùå Invalid choice.\")"
      ]
    }
  ]
}